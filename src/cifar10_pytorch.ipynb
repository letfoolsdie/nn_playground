{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as Im\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = unpickle(\"../data/processed_data/all_cf_batches.p\")\n",
    "\n",
    "with open(\"../data/processed_data/all_labels.txt\") as lab:\n",
    "    train_labels = [int(i) for i in lab.read().split()]\n",
    "    \n",
    "label_names = {\n",
    "    0:'airplane',\n",
    "    1:'automobile',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 12411\n",
    "\n",
    "# print(label_names[Y_train[ind]])\n",
    "# plt.imshow(X_train[ind]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, X_test, train_labels, Y_test = train_data[:45000], train_data[45000:], train_labels[:45000], train_labels[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "(40000, 32, 32, 3)\n",
      "====================\n",
      "Validation data:\n",
      "(5000, 32, 32, 3)\n",
      "====================\n",
      "Test data:\n",
      "(5000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_data[:40000], train_data[40000:], train_labels[:40000], train_labels[40000:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(X_train.shape)\n",
    "print(\"=\"*20)\n",
    "print(\"Validation data:\")\n",
    "print(X_val.shape)\n",
    "print(\"=\"*20)\n",
    "print(\"Test data:\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels \n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "#         image = Im.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "train_dataset = Cifar(X_train, Y_train, transform=transform)\n",
    "test_dataset = Cifar(X_test, Y_test, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.fc = nn.Linear(8 * 8 * 32, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x.view(-1, 8 * 8 * 32)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.302\n",
      "[1,   400] loss: 2.300\n",
      "[1,   600] loss: 2.288\n",
      "[1,   800] loss: 2.237\n",
      "[1,  1000] loss: 2.119\n",
      "[1,  1200] loss: 2.083\n",
      "[1,  1400] loss: 2.027\n",
      "[1,  1600] loss: 2.010\n",
      "[1,  1800] loss: 1.969\n",
      "[1,  2000] loss: 1.978\n",
      "[1,  2200] loss: 1.914\n",
      "[1,  2400] loss: 1.832\n",
      "[1,  2600] loss: 1.864\n",
      "[1,  2800] loss: 1.815\n",
      "[1,  3000] loss: 1.842\n",
      "[1,  3200] loss: 1.744\n",
      "[1,  3400] loss: 1.703\n",
      "[1,  3600] loss: 1.669\n",
      "[1,  3800] loss: 1.673\n",
      "[1,  4000] loss: 1.636\n",
      "[1,  4200] loss: 1.606\n",
      "[1,  4400] loss: 1.593\n",
      "[1,  4600] loss: 1.570\n",
      "[1,  4800] loss: 1.567\n",
      "[1,  5000] loss: 1.559\n",
      "[2,   200] loss: 1.529\n",
      "[2,   400] loss: 1.527\n",
      "[2,   600] loss: 1.504\n",
      "[2,   800] loss: 1.541\n",
      "[2,  1000] loss: 1.478\n",
      "[2,  1200] loss: 1.457\n",
      "[2,  1400] loss: 1.501\n",
      "[2,  1600] loss: 1.460\n",
      "[2,  1800] loss: 1.447\n",
      "[2,  2000] loss: 1.453\n",
      "[2,  2200] loss: 1.440\n",
      "[2,  2400] loss: 1.417\n",
      "[2,  2600] loss: 1.446\n",
      "[2,  2800] loss: 1.391\n",
      "[2,  3000] loss: 1.377\n",
      "[2,  3200] loss: 1.432\n",
      "[2,  3400] loss: 1.348\n",
      "[2,  3600] loss: 1.406\n",
      "[2,  3800] loss: 1.380\n",
      "[2,  4000] loss: 1.333\n",
      "[2,  4200] loss: 1.380\n",
      "[2,  4400] loss: 1.347\n",
      "[2,  4600] loss: 1.326\n",
      "[2,  4800] loss: 1.304\n",
      "[2,  5000] loss: 1.382\n",
      "[3,   200] loss: 1.264\n",
      "[3,   400] loss: 1.283\n",
      "[3,   600] loss: 1.262\n",
      "[3,   800] loss: 1.298\n",
      "[3,  1000] loss: 1.229\n",
      "[3,  1200] loss: 1.242\n",
      "[3,  1400] loss: 1.266\n",
      "[3,  1600] loss: 1.315\n",
      "[3,  1800] loss: 1.252\n",
      "[3,  2000] loss: 1.207\n",
      "[3,  2200] loss: 1.222\n",
      "[3,  2400] loss: 1.271\n",
      "[3,  2600] loss: 1.236\n",
      "[3,  2800] loss: 1.222\n",
      "[3,  3000] loss: 1.163\n",
      "[3,  3200] loss: 1.218\n",
      "[3,  3400] loss: 1.252\n",
      "[3,  3600] loss: 1.211\n",
      "[3,  3800] loss: 1.194\n",
      "[3,  4000] loss: 1.177\n",
      "[3,  4200] loss: 1.214\n",
      "[3,  4400] loss: 1.209\n",
      "[3,  4600] loss: 1.166\n",
      "[3,  4800] loss: 1.207\n",
      "[3,  5000] loss: 1.202\n",
      "[4,   200] loss: 1.119\n",
      "[4,   400] loss: 1.102\n",
      "[4,   600] loss: 1.098\n",
      "[4,   800] loss: 1.128\n",
      "[4,  1000] loss: 1.092\n",
      "[4,  1200] loss: 1.124\n",
      "[4,  1400] loss: 1.167\n",
      "[4,  1600] loss: 1.135\n",
      "[4,  1800] loss: 1.094\n",
      "[4,  2000] loss: 1.129\n",
      "[4,  2200] loss: 1.091\n",
      "[4,  2400] loss: 1.051\n",
      "[4,  2600] loss: 1.142\n",
      "[4,  2800] loss: 1.094\n",
      "[4,  3000] loss: 1.106\n",
      "[4,  3200] loss: 1.087\n",
      "[4,  3400] loss: 1.119\n",
      "[4,  3600] loss: 1.100\n",
      "[4,  3800] loss: 1.056\n",
      "[4,  4000] loss: 1.077\n",
      "[4,  4200] loss: 1.069\n",
      "[4,  4400] loss: 1.165\n",
      "[4,  4600] loss: 1.055\n",
      "[4,  4800] loss: 1.070\n",
      "[4,  5000] loss: 1.097\n",
      "[5,   200] loss: 1.036\n",
      "[5,   400] loss: 0.990\n",
      "[5,   600] loss: 1.053\n",
      "[5,   800] loss: 1.000\n",
      "[5,  1000] loss: 1.023\n",
      "[5,  1200] loss: 1.058\n",
      "[5,  1400] loss: 1.005\n",
      "[5,  1600] loss: 1.019\n",
      "[5,  1800] loss: 1.059\n",
      "[5,  2000] loss: 0.963\n",
      "[5,  2200] loss: 1.016\n",
      "[5,  2400] loss: 0.990\n",
      "[5,  2600] loss: 1.029\n",
      "[5,  2800] loss: 0.988\n",
      "[5,  3000] loss: 0.994\n",
      "[5,  3200] loss: 1.053\n",
      "[5,  3400] loss: 0.984\n",
      "[5,  3600] loss: 0.967\n",
      "[5,  3800] loss: 1.030\n",
      "[5,  4000] loss: 0.983\n",
      "[5,  4200] loss: 1.019\n",
      "[5,  4400] loss: 0.944\n",
      "[5,  4600] loss: 1.036\n",
      "[5,  4800] loss: 0.992\n",
      "[5,  5000] loss: 0.998\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader_train, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in dataloader_train:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
