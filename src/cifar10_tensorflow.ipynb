{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/letfoolsdie/virt_envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image as Im\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = unpickle(\"../data/processed_data/all_cf_batches.p\")\n",
    "\n",
    "with open(\"../data/processed_data/all_labels.txt\") as lab:\n",
    "    train_labels = [int(i) for i in lab.read().split()]\n",
    "    \n",
    "label_names = {\n",
    "    0:'airplane',\n",
    "    1:'automobile',\n",
    "    2:'bird',\n",
    "    3:'cat',\n",
    "    4:'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(data, num_classes):\n",
    "    temp = np.zeros((len(data), num_classes))\n",
    "    temp[range(len(data)), data] = 1\n",
    "    return temp\n",
    "\n",
    "train_labels = to_categorical(train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, X_test, train_labels, Y_test = train_data[:45000], train_data[45000:], train_labels[:45000], train_labels[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_data[:40000], train_data[40000:], train_labels[:40000], train_labels[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "(40000, 32, 32, 3)\n",
      "====================\n",
      "Validation data:\n",
      "(5000, 32, 32, 3)\n",
      "====================\n",
      "Test data:\n",
      "(5000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\")\n",
    "print(X_train.shape)\n",
    "print(\"=\"*20)\n",
    "print(\"Validation data:\")\n",
    "print(X_val.shape)\n",
    "print(\"=\"*20)\n",
    "print(\"Test data:\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_h, img_w, img_c = X_train.shape[1:]\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, shape=[None, img_h, img_w, img_c])\n",
    "Y_input = tf.placeholder(tf.float32, shape=[None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_inp, Y_inp):\n",
    "    inp = X_inp\n",
    "    output = Y_inp\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=inp,\n",
    "        filters=16,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=16,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)    \n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Convolutional Layer #3\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "        \n",
    "    # Convolutional Layer #4\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=conv3,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)    \n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Dense layer:\n",
    "    flat = tf.contrib.layers.flatten(pool2)\n",
    "    logits = tf.layers.dense(inputs=flat, units=10, activation=None)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = build_model(X_input, Y_input)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "# Compute loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y_input))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y_input, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar = np.array(list(range(30)))\n",
    "\n",
    "def get_next_batch(X, Y, step, batch_size):\n",
    "    start = ((step - 1) * batch_size) % X.shape[0]\n",
    "    end = start + batch_size\n",
    "    return X[start:end], Y[start:end]\n",
    "\n",
    "# for i in range(100):\n",
    "#     print(get_next_batch(tar, i, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2.3003, Training Accuracy= 0.103\n",
      "Step 20, Minibatch Loss= 2.2165, Training Accuracy= 0.192\n",
      "Step 40, Minibatch Loss= 2.0586, Training Accuracy= 0.258\n",
      "Step 60, Minibatch Loss= 2.0478, Training Accuracy= 0.259\n",
      "Step 80, Minibatch Loss= 1.9771, Training Accuracy= 0.302\n",
      "Step 100, Minibatch Loss= 1.9527, Training Accuracy= 0.308\n",
      "Step 120, Minibatch Loss= 1.8222, Training Accuracy= 0.350\n",
      "Step 140, Minibatch Loss= 1.7773, Training Accuracy= 0.365\n",
      "Step 160, Minibatch Loss= 1.7843, Training Accuracy= 0.371\n",
      "Step 180, Minibatch Loss= 1.7575, Training Accuracy= 0.367\n",
      "Step 200, Minibatch Loss= 1.7206, Training Accuracy= 0.389\n",
      "Step 220, Minibatch Loss= 1.7332, Training Accuracy= 0.366\n",
      "Step 240, Minibatch Loss= 1.6795, Training Accuracy= 0.395\n",
      "Step 260, Minibatch Loss= 1.6454, Training Accuracy= 0.424\n",
      "Step 280, Minibatch Loss= 1.6104, Training Accuracy= 0.427\n",
      "Step 300, Minibatch Loss= 1.6298, Training Accuracy= 0.415\n",
      "Step 320, Minibatch Loss= 1.6729, Training Accuracy= 0.401\n",
      "Step 340, Minibatch Loss= 1.6364, Training Accuracy= 0.427\n",
      "Step 360, Minibatch Loss= 1.6059, Training Accuracy= 0.423\n",
      "Step 380, Minibatch Loss= 1.5774, Training Accuracy= 0.444\n",
      "Step 400, Minibatch Loss= 1.6120, Training Accuracy= 0.433\n",
      "Step 420, Minibatch Loss= 1.5662, Training Accuracy= 0.443\n",
      "Step 440, Minibatch Loss= 1.5789, Training Accuracy= 0.429\n",
      "Step 460, Minibatch Loss= 1.5414, Training Accuracy= 0.443\n",
      "Step 480, Minibatch Loss= 1.5050, Training Accuracy= 0.466\n",
      "Step 500, Minibatch Loss= 1.5138, Training Accuracy= 0.459\n",
      "Step 520, Minibatch Loss= 1.5810, Training Accuracy= 0.445\n",
      "Step 540, Minibatch Loss= 1.5100, Training Accuracy= 0.460\n",
      "Step 560, Minibatch Loss= 1.5329, Training Accuracy= 0.447\n",
      "Step 580, Minibatch Loss= 1.4592, Training Accuracy= 0.479\n",
      "Step 600, Minibatch Loss= 1.5425, Training Accuracy= 0.454\n",
      "Step 620, Minibatch Loss= 1.5616, Training Accuracy= 0.445\n",
      "Step 640, Minibatch Loss= 1.4453, Training Accuracy= 0.485\n",
      "Step 660, Minibatch Loss= 1.4972, Training Accuracy= 0.472\n",
      "Step 680, Minibatch Loss= 1.4279, Training Accuracy= 0.479\n",
      "Step 700, Minibatch Loss= 1.4570, Training Accuracy= 0.480\n",
      "Step 720, Minibatch Loss= 1.4087, Training Accuracy= 0.502\n",
      "Step 740, Minibatch Loss= 1.3869, Training Accuracy= 0.512\n",
      "Step 760, Minibatch Loss= 1.4046, Training Accuracy= 0.501\n",
      "Step 780, Minibatch Loss= 1.5367, Training Accuracy= 0.469\n",
      "Step 800, Minibatch Loss= 1.3952, Training Accuracy= 0.505\n",
      "Step 820, Minibatch Loss= 1.3955, Training Accuracy= 0.504\n",
      "Step 840, Minibatch Loss= 1.3478, Training Accuracy= 0.525\n",
      "Step 860, Minibatch Loss= 1.3405, Training Accuracy= 0.526\n",
      "Step 880, Minibatch Loss= 1.3257, Training Accuracy= 0.542\n",
      "Step 900, Minibatch Loss= 1.3094, Training Accuracy= 0.535\n",
      "Step 920, Minibatch Loss= 1.2984, Training Accuracy= 0.543\n",
      "Step 940, Minibatch Loss= 1.3059, Training Accuracy= 0.536\n",
      "Step 960, Minibatch Loss= 1.2912, Training Accuracy= 0.539\n",
      "Step 980, Minibatch Loss= 1.2793, Training Accuracy= 0.545\n",
      "Step 1000, Minibatch Loss= 1.2791, Training Accuracy= 0.560\n",
      "Step 1020, Minibatch Loss= 1.2749, Training Accuracy= 0.551\n",
      "Step 1040, Minibatch Loss= 1.2927, Training Accuracy= 0.549\n",
      "Step 1060, Minibatch Loss= 1.2491, Training Accuracy= 0.568\n",
      "Step 1080, Minibatch Loss= 1.2588, Training Accuracy= 0.546\n",
      "Step 1100, Minibatch Loss= 1.2182, Training Accuracy= 0.573\n",
      "Step 1120, Minibatch Loss= 1.2234, Training Accuracy= 0.568\n",
      "Step 1140, Minibatch Loss= 1.2972, Training Accuracy= 0.545\n",
      "Step 1160, Minibatch Loss= 1.2146, Training Accuracy= 0.566\n",
      "Step 1180, Minibatch Loss= 1.2408, Training Accuracy= 0.561\n",
      "Step 1200, Minibatch Loss= 1.2279, Training Accuracy= 0.567\n",
      "Step 1220, Minibatch Loss= 1.1800, Training Accuracy= 0.587\n",
      "Step 1240, Minibatch Loss= 1.1888, Training Accuracy= 0.582\n",
      "Step 1260, Minibatch Loss= 1.2199, Training Accuracy= 0.565\n",
      "Step 1280, Minibatch Loss= 1.2984, Training Accuracy= 0.525\n",
      "Step 1300, Minibatch Loss= 1.2084, Training Accuracy= 0.573\n",
      "Step 1320, Minibatch Loss= 1.1776, Training Accuracy= 0.587\n",
      "Step 1340, Minibatch Loss= 1.2052, Training Accuracy= 0.573\n",
      "Step 1360, Minibatch Loss= 1.2196, Training Accuracy= 0.570\n",
      "Step 1380, Minibatch Loss= 1.1682, Training Accuracy= 0.594\n",
      "Step 1400, Minibatch Loss= 1.1914, Training Accuracy= 0.584\n",
      "Step 1420, Minibatch Loss= 1.2201, Training Accuracy= 0.573\n",
      "Step 1440, Minibatch Loss= 1.1626, Training Accuracy= 0.584\n",
      "Step 1460, Minibatch Loss= 1.2035, Training Accuracy= 0.571\n",
      "Step 1480, Minibatch Loss= 1.2084, Training Accuracy= 0.570\n",
      "Step 1500, Minibatch Loss= 1.1570, Training Accuracy= 0.595\n",
      "Step 1520, Minibatch Loss= 1.1704, Training Accuracy= 0.595\n",
      "Step 1540, Minibatch Loss= 1.1853, Training Accuracy= 0.582\n",
      "Step 1560, Minibatch Loss= 1.1612, Training Accuracy= 0.592\n",
      "Step 1580, Minibatch Loss= 1.1750, Training Accuracy= 0.591\n",
      "Step 1600, Minibatch Loss= 1.1182, Training Accuracy= 0.608\n",
      "Step 1620, Minibatch Loss= 1.1338, Training Accuracy= 0.602\n",
      "Step 1640, Minibatch Loss= 1.1377, Training Accuracy= 0.597\n",
      "Step 1660, Minibatch Loss= 1.1452, Training Accuracy= 0.601\n",
      "Step 1680, Minibatch Loss= 1.1203, Training Accuracy= 0.607\n",
      "Step 1700, Minibatch Loss= 1.1101, Training Accuracy= 0.609\n",
      "Step 1720, Minibatch Loss= 1.1258, Training Accuracy= 0.601\n",
      "Step 1740, Minibatch Loss= 1.1499, Training Accuracy= 0.594\n",
      "Step 1760, Minibatch Loss= 1.1463, Training Accuracy= 0.599\n",
      "Step 1780, Minibatch Loss= 1.1147, Training Accuracy= 0.609\n",
      "Step 1800, Minibatch Loss= 1.1201, Training Accuracy= 0.605\n",
      "Step 1820, Minibatch Loss= 1.1000, Training Accuracy= 0.618\n",
      "Step 1840, Minibatch Loss= 1.0873, Training Accuracy= 0.623\n",
      "Step 1860, Minibatch Loss= 1.1026, Training Accuracy= 0.608\n",
      "Step 1880, Minibatch Loss= 1.1042, Training Accuracy= 0.604\n",
      "Step 1900, Minibatch Loss= 1.1111, Training Accuracy= 0.613\n",
      "Step 1920, Minibatch Loss= 1.1449, Training Accuracy= 0.591\n",
      "Step 1940, Minibatch Loss= 1.1004, Training Accuracy= 0.613\n",
      "Step 1960, Minibatch Loss= 1.0721, Training Accuracy= 0.622\n",
      "Step 1980, Minibatch Loss= 1.0805, Training Accuracy= 0.619\n",
      "Step 2000, Minibatch Loss= 1.1103, Training Accuracy= 0.615\n",
      "Step 2020, Minibatch Loss= 1.0796, Training Accuracy= 0.622\n",
      "Step 2040, Minibatch Loss= 1.0918, Training Accuracy= 0.611\n",
      "Step 2060, Minibatch Loss= 1.1078, Training Accuracy= 0.606\n",
      "Step 2080, Minibatch Loss= 1.1244, Training Accuracy= 0.609\n",
      "Step 2100, Minibatch Loss= 1.0474, Training Accuracy= 0.631\n",
      "Step 2120, Minibatch Loss= 1.0906, Training Accuracy= 0.622\n",
      "Step 2140, Minibatch Loss= 1.0649, Training Accuracy= 0.628\n",
      "Step 2160, Minibatch Loss= 1.0467, Training Accuracy= 0.628\n",
      "Step 2180, Minibatch Loss= 1.1042, Training Accuracy= 0.612\n",
      "Step 2200, Minibatch Loss= 1.0660, Training Accuracy= 0.627\n",
      "Step 2220, Minibatch Loss= 1.0411, Training Accuracy= 0.633\n",
      "Step 2240, Minibatch Loss= 1.0785, Training Accuracy= 0.620\n",
      "Step 2260, Minibatch Loss= 1.0729, Training Accuracy= 0.622\n",
      "Step 2280, Minibatch Loss= 1.0663, Training Accuracy= 0.623\n",
      "Step 2300, Minibatch Loss= 1.0563, Training Accuracy= 0.629\n",
      "Step 2320, Minibatch Loss= 1.0587, Training Accuracy= 0.623\n",
      "Step 2340, Minibatch Loss= 1.0562, Training Accuracy= 0.623\n",
      "Step 2360, Minibatch Loss= 1.0098, Training Accuracy= 0.641\n",
      "Step 2380, Minibatch Loss= 1.0423, Training Accuracy= 0.629\n",
      "Step 2400, Minibatch Loss= 1.0174, Training Accuracy= 0.638\n",
      "Step 2420, Minibatch Loss= 1.1380, Training Accuracy= 0.597\n",
      "Step 2440, Minibatch Loss= 1.1225, Training Accuracy= 0.598\n",
      "Step 2460, Minibatch Loss= 1.0263, Training Accuracy= 0.630\n",
      "Step 2480, Minibatch Loss= 1.0210, Training Accuracy= 0.638\n",
      "Step 2500, Minibatch Loss= 1.0996, Training Accuracy= 0.609\n",
      "Step 2520, Minibatch Loss= 1.0782, Training Accuracy= 0.617\n",
      "Step 2540, Minibatch Loss= 1.0015, Training Accuracy= 0.647\n",
      "Step 2560, Minibatch Loss= 1.0103, Training Accuracy= 0.642\n",
      "Step 2580, Minibatch Loss= 1.0381, Training Accuracy= 0.629\n",
      "Step 2600, Minibatch Loss= 1.0034, Training Accuracy= 0.648\n",
      "Step 2620, Minibatch Loss= 1.0390, Training Accuracy= 0.637\n",
      "Step 2640, Minibatch Loss= 1.0361, Training Accuracy= 0.640\n",
      "Step 2660, Minibatch Loss= 1.0293, Training Accuracy= 0.636\n",
      "Step 2680, Minibatch Loss= 1.0309, Training Accuracy= 0.637\n",
      "Step 2700, Minibatch Loss= 1.0142, Training Accuracy= 0.645\n",
      "Step 2720, Minibatch Loss= 1.0532, Training Accuracy= 0.628\n",
      "Step 2740, Minibatch Loss= 1.0255, Training Accuracy= 0.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2760, Minibatch Loss= 1.0064, Training Accuracy= 0.647\n",
      "Step 2780, Minibatch Loss= 1.0592, Training Accuracy= 0.634\n",
      "Step 2800, Minibatch Loss= 1.0420, Training Accuracy= 0.643\n",
      "Step 2820, Minibatch Loss= 1.0248, Training Accuracy= 0.644\n",
      "Step 2840, Minibatch Loss= 1.0118, Training Accuracy= 0.643\n",
      "Step 2860, Minibatch Loss= 1.0772, Training Accuracy= 0.622\n",
      "Step 2880, Minibatch Loss= 1.0026, Training Accuracy= 0.648\n",
      "Step 2900, Minibatch Loss= 1.0488, Training Accuracy= 0.636\n",
      "Step 2920, Minibatch Loss= 1.0217, Training Accuracy= 0.641\n",
      "Step 2940, Minibatch Loss= 1.0070, Training Accuracy= 0.648\n",
      "Step 2960, Minibatch Loss= 1.0056, Training Accuracy= 0.650\n",
      "Step 2980, Minibatch Loss= 0.9825, Training Accuracy= 0.655\n",
      "Step 3000, Minibatch Loss= 1.0776, Training Accuracy= 0.618\n",
      "Step 3020, Minibatch Loss= 0.9783, Training Accuracy= 0.657\n",
      "Step 3040, Minibatch Loss= 1.0056, Training Accuracy= 0.648\n",
      "Step 3060, Minibatch Loss= 1.0890, Training Accuracy= 0.621\n",
      "Step 3080, Minibatch Loss= 1.0008, Training Accuracy= 0.649\n",
      "Step 3100, Minibatch Loss= 0.9966, Training Accuracy= 0.644\n",
      "Step 3120, Minibatch Loss= 0.9949, Training Accuracy= 0.657\n",
      "Step 3140, Minibatch Loss= 0.9873, Training Accuracy= 0.658\n",
      "Step 3160, Minibatch Loss= 1.0031, Training Accuracy= 0.650\n",
      "Step 3180, Minibatch Loss= 1.0364, Training Accuracy= 0.627\n",
      "Step 3200, Minibatch Loss= 0.9833, Training Accuracy= 0.656\n",
      "Step 3220, Minibatch Loss= 0.9823, Training Accuracy= 0.650\n",
      "Step 3240, Minibatch Loss= 0.9817, Training Accuracy= 0.654\n",
      "Step 3260, Minibatch Loss= 1.0405, Training Accuracy= 0.636\n",
      "Step 3280, Minibatch Loss= 1.0476, Training Accuracy= 0.637\n",
      "Step 3300, Minibatch Loss= 0.9824, Training Accuracy= 0.653\n",
      "Step 3320, Minibatch Loss= 1.0745, Training Accuracy= 0.625\n",
      "Step 3340, Minibatch Loss= 0.9595, Training Accuracy= 0.670\n",
      "Step 3360, Minibatch Loss= 0.9880, Training Accuracy= 0.656\n",
      "Step 3380, Minibatch Loss= 0.9741, Training Accuracy= 0.666\n",
      "Step 3400, Minibatch Loss= 0.9641, Training Accuracy= 0.662\n",
      "Step 3420, Minibatch Loss= 0.9818, Training Accuracy= 0.658\n",
      "Step 3440, Minibatch Loss= 0.9637, Training Accuracy= 0.664\n",
      "Step 3460, Minibatch Loss= 0.9761, Training Accuracy= 0.659\n",
      "Step 3480, Minibatch Loss= 0.9541, Training Accuracy= 0.662\n",
      "Step 3500, Minibatch Loss= 0.9793, Training Accuracy= 0.660\n",
      "Step 3520, Minibatch Loss= 0.9638, Training Accuracy= 0.664\n",
      "Step 3540, Minibatch Loss= 0.9552, Training Accuracy= 0.671\n",
      "Step 3560, Minibatch Loss= 0.9492, Training Accuracy= 0.665\n",
      "Step 3580, Minibatch Loss= 0.9701, Training Accuracy= 0.659\n",
      "Step 3600, Minibatch Loss= 0.9893, Training Accuracy= 0.644\n",
      "Step 3620, Minibatch Loss= 0.9941, Training Accuracy= 0.655\n",
      "Step 3640, Minibatch Loss= 0.9846, Training Accuracy= 0.655\n",
      "Step 3660, Minibatch Loss= 1.0081, Training Accuracy= 0.657\n",
      "Step 3680, Minibatch Loss= 0.9701, Training Accuracy= 0.656\n",
      "Step 3700, Minibatch Loss= 0.9617, Training Accuracy= 0.662\n",
      "Step 3720, Minibatch Loss= 0.9497, Training Accuracy= 0.670\n",
      "Step 3740, Minibatch Loss= 0.9890, Training Accuracy= 0.660\n",
      "Step 3760, Minibatch Loss= 0.9649, Training Accuracy= 0.662\n",
      "Step 3780, Minibatch Loss= 1.0000, Training Accuracy= 0.652\n",
      "Step 3800, Minibatch Loss= 0.9836, Training Accuracy= 0.661\n",
      "Step 3820, Minibatch Loss= 0.9691, Training Accuracy= 0.658\n",
      "Step 3840, Minibatch Loss= 0.9591, Training Accuracy= 0.672\n",
      "Step 3860, Minibatch Loss= 0.9582, Training Accuracy= 0.668\n",
      "Step 3880, Minibatch Loss= 0.9621, Training Accuracy= 0.665\n",
      "Step 3900, Minibatch Loss= 0.9689, Training Accuracy= 0.661\n",
      "Step 3920, Minibatch Loss= 0.9539, Training Accuracy= 0.666\n",
      "Step 3940, Minibatch Loss= 0.9425, Training Accuracy= 0.670\n",
      "Step 3960, Minibatch Loss= 0.9845, Training Accuracy= 0.661\n",
      "Step 3980, Minibatch Loss= 0.9634, Training Accuracy= 0.658\n",
      "Step 4000, Minibatch Loss= 0.9561, Training Accuracy= 0.655\n",
      "Step 4020, Minibatch Loss= 0.9640, Training Accuracy= 0.664\n",
      "Step 4040, Minibatch Loss= 0.9465, Training Accuracy= 0.667\n",
      "Step 4060, Minibatch Loss= 0.9933, Training Accuracy= 0.653\n",
      "Step 4080, Minibatch Loss= 0.9790, Training Accuracy= 0.652\n",
      "Step 4100, Minibatch Loss= 0.9455, Training Accuracy= 0.671\n",
      "Step 4120, Minibatch Loss= 0.9443, Training Accuracy= 0.672\n",
      "Step 4140, Minibatch Loss= 0.9497, Training Accuracy= 0.668\n",
      "Step 4160, Minibatch Loss= 0.9318, Training Accuracy= 0.668\n",
      "Step 4180, Minibatch Loss= 0.9552, Training Accuracy= 0.668\n",
      "Step 4200, Minibatch Loss= 0.9483, Training Accuracy= 0.674\n",
      "Step 4220, Minibatch Loss= 0.9883, Training Accuracy= 0.653\n",
      "Step 4240, Minibatch Loss= 0.9633, Training Accuracy= 0.668\n",
      "Step 4260, Minibatch Loss= 0.9590, Training Accuracy= 0.672\n",
      "Step 4280, Minibatch Loss= 0.9362, Training Accuracy= 0.672\n",
      "Step 4300, Minibatch Loss= 0.9191, Training Accuracy= 0.678\n",
      "Step 4320, Minibatch Loss= 0.9472, Training Accuracy= 0.670\n",
      "Step 4340, Minibatch Loss= 0.9486, Training Accuracy= 0.674\n",
      "Step 4360, Minibatch Loss= 0.9595, Training Accuracy= 0.664\n",
      "Step 4380, Minibatch Loss= 0.9294, Training Accuracy= 0.683\n",
      "Step 4400, Minibatch Loss= 0.9316, Training Accuracy= 0.676\n",
      "Step 4420, Minibatch Loss= 1.0479, Training Accuracy= 0.634\n",
      "Step 4440, Minibatch Loss= 0.9479, Training Accuracy= 0.667\n",
      "Step 4460, Minibatch Loss= 0.9303, Training Accuracy= 0.680\n",
      "Step 4480, Minibatch Loss= 0.9260, Training Accuracy= 0.677\n",
      "Step 4500, Minibatch Loss= 0.9253, Training Accuracy= 0.678\n",
      "Step 4520, Minibatch Loss= 0.9315, Training Accuracy= 0.673\n",
      "Step 4540, Minibatch Loss= 0.9640, Training Accuracy= 0.661\n",
      "Step 4560, Minibatch Loss= 0.9337, Training Accuracy= 0.673\n",
      "Step 4580, Minibatch Loss= 0.9398, Training Accuracy= 0.678\n",
      "Step 4600, Minibatch Loss= 0.9254, Training Accuracy= 0.681\n",
      "Step 4620, Minibatch Loss= 0.9435, Training Accuracy= 0.668\n",
      "Step 4640, Minibatch Loss= 0.9514, Training Accuracy= 0.669\n",
      "Step 4660, Minibatch Loss= 0.9505, Training Accuracy= 0.666\n",
      "Step 4680, Minibatch Loss= 0.9429, Training Accuracy= 0.669\n",
      "Step 4700, Minibatch Loss= 0.9149, Training Accuracy= 0.683\n",
      "Step 4720, Minibatch Loss= 0.9188, Training Accuracy= 0.674\n",
      "Step 4740, Minibatch Loss= 0.9705, Training Accuracy= 0.665\n",
      "Step 4760, Minibatch Loss= 0.9209, Training Accuracy= 0.681\n",
      "Step 4780, Minibatch Loss= 0.9325, Training Accuracy= 0.673\n",
      "Step 4800, Minibatch Loss= 0.9169, Training Accuracy= 0.675\n",
      "Step 4820, Minibatch Loss= 0.9624, Training Accuracy= 0.664\n",
      "Step 4840, Minibatch Loss= 0.9655, Training Accuracy= 0.667\n",
      "Step 4860, Minibatch Loss= 0.9077, Training Accuracy= 0.683\n",
      "Step 4880, Minibatch Loss= 0.9611, Training Accuracy= 0.663\n",
      "Step 4900, Minibatch Loss= 0.9347, Training Accuracy= 0.676\n",
      "Step 4920, Minibatch Loss= 0.9997, Training Accuracy= 0.658\n",
      "Step 4940, Minibatch Loss= 0.9540, Training Accuracy= 0.662\n",
      "Step 4960, Minibatch Loss= 0.9070, Training Accuracy= 0.684\n",
      "Step 4980, Minibatch Loss= 0.9269, Training Accuracy= 0.680\n",
      "Step 5000, Minibatch Loss= 1.0169, Training Accuracy= 0.651\n",
      "Step 5020, Minibatch Loss= 0.9502, Training Accuracy= 0.670\n",
      "Step 5040, Minibatch Loss= 0.9250, Training Accuracy= 0.683\n",
      "Step 5060, Minibatch Loss= 0.9301, Training Accuracy= 0.680\n",
      "Step 5080, Minibatch Loss= 0.9391, Training Accuracy= 0.667\n",
      "Step 5100, Minibatch Loss= 0.9106, Training Accuracy= 0.686\n",
      "Step 5120, Minibatch Loss= 0.9300, Training Accuracy= 0.680\n",
      "Step 5140, Minibatch Loss= 0.9430, Training Accuracy= 0.677\n",
      "Step 5160, Minibatch Loss= 0.9704, Training Accuracy= 0.662\n",
      "Step 5180, Minibatch Loss= 0.9771, Training Accuracy= 0.654\n",
      "Step 5200, Minibatch Loss= 0.9181, Training Accuracy= 0.682\n",
      "Step 5220, Minibatch Loss= 0.9545, Training Accuracy= 0.667\n",
      "Step 5240, Minibatch Loss= 0.9781, Training Accuracy= 0.653\n",
      "Step 5260, Minibatch Loss= 0.9589, Training Accuracy= 0.664\n",
      "Step 5280, Minibatch Loss= 0.9508, Training Accuracy= 0.666\n",
      "Step 5300, Minibatch Loss= 0.9470, Training Accuracy= 0.671\n",
      "Step 5320, Minibatch Loss= 0.9528, Training Accuracy= 0.663\n",
      "Step 5340, Minibatch Loss= 0.9465, Training Accuracy= 0.666\n",
      "Step 5360, Minibatch Loss= 0.9598, Training Accuracy= 0.673\n",
      "Step 5380, Minibatch Loss= 0.9202, Training Accuracy= 0.681\n",
      "Step 5400, Minibatch Loss= 0.9288, Training Accuracy= 0.678\n",
      "Step 5420, Minibatch Loss= 0.9667, Training Accuracy= 0.660\n",
      "Step 5440, Minibatch Loss= 0.9130, Training Accuracy= 0.683\n",
      "Step 5460, Minibatch Loss= 0.9188, Training Accuracy= 0.681\n",
      "Step 5480, Minibatch Loss= 0.9345, Training Accuracy= 0.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500, Minibatch Loss= 1.0154, Training Accuracy= 0.652\n",
      "Step 5520, Minibatch Loss= 0.9212, Training Accuracy= 0.681\n",
      "Step 5540, Minibatch Loss= 0.9042, Training Accuracy= 0.686\n",
      "Step 5560, Minibatch Loss= 0.9450, Training Accuracy= 0.679\n",
      "Step 5580, Minibatch Loss= 0.9178, Training Accuracy= 0.682\n",
      "Step 5600, Minibatch Loss= 0.9206, Training Accuracy= 0.680\n",
      "Step 5620, Minibatch Loss= 0.9522, Training Accuracy= 0.675\n",
      "Step 5640, Minibatch Loss= 0.9579, Training Accuracy= 0.667\n",
      "Step 5660, Minibatch Loss= 0.9051, Training Accuracy= 0.688\n",
      "Step 5680, Minibatch Loss= 0.9667, Training Accuracy= 0.663\n",
      "Step 5700, Minibatch Loss= 0.9215, Training Accuracy= 0.677\n",
      "Step 5720, Minibatch Loss= 0.8892, Training Accuracy= 0.689\n",
      "Step 5740, Minibatch Loss= 0.9040, Training Accuracy= 0.691\n",
      "Step 5760, Minibatch Loss= 1.0023, Training Accuracy= 0.664\n",
      "Step 5780, Minibatch Loss= 1.0071, Training Accuracy= 0.664\n",
      "Step 5800, Minibatch Loss= 0.9026, Training Accuracy= 0.695\n",
      "Step 5820, Minibatch Loss= 0.9366, Training Accuracy= 0.676\n",
      "Step 5840, Minibatch Loss= 0.9020, Training Accuracy= 0.695\n",
      "Step 5860, Minibatch Loss= 0.9133, Training Accuracy= 0.683\n",
      "Step 5880, Minibatch Loss= 0.9469, Training Accuracy= 0.678\n",
      "Step 5900, Minibatch Loss= 0.9233, Training Accuracy= 0.686\n",
      "Step 5920, Minibatch Loss= 0.9416, Training Accuracy= 0.672\n",
      "Step 5940, Minibatch Loss= 0.9077, Training Accuracy= 0.688\n",
      "Step 5960, Minibatch Loss= 0.9697, Training Accuracy= 0.671\n",
      "Step 5980, Minibatch Loss= 0.8937, Training Accuracy= 0.686\n",
      "Step 6000, Minibatch Loss= 0.9159, Training Accuracy= 0.690\n",
      "Step 6020, Minibatch Loss= 0.9091, Training Accuracy= 0.689\n",
      "Step 6040, Minibatch Loss= 0.9134, Training Accuracy= 0.686\n",
      "Step 6060, Minibatch Loss= 0.9258, Training Accuracy= 0.677\n",
      "Step 6080, Minibatch Loss= 0.9219, Training Accuracy= 0.685\n",
      "Step 6100, Minibatch Loss= 0.9398, Training Accuracy= 0.669\n",
      "Step 6120, Minibatch Loss= 0.9137, Training Accuracy= 0.689\n",
      "Step 6140, Minibatch Loss= 0.9329, Training Accuracy= 0.680\n",
      "Step 6160, Minibatch Loss= 0.9373, Training Accuracy= 0.681\n",
      "Step 6180, Minibatch Loss= 0.8725, Training Accuracy= 0.702\n",
      "Step 6200, Minibatch Loss= 0.9158, Training Accuracy= 0.684\n",
      "Step 6220, Minibatch Loss= 0.9209, Training Accuracy= 0.685\n",
      "Step 6240, Minibatch Loss= 0.9441, Training Accuracy= 0.676\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.6678\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "num_steps = epochs * X_train.shape[0] // batch_size\n",
    "display_step = 20\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = get_next_batch(X_train, Y_train, step, batch_size)\n",
    "#         print(batch_x)\n",
    "#         print(\"=\"*20)\n",
    "#         print(batch_y)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X_input: batch_x, Y_input: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            val_loss, acc = sess.run([loss, accuracy], feed_dict={X_input: X_val,\n",
    "                                                                 Y_input: Y_val})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(val_loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X_input: X_test,\n",
    "                                      Y_input: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
